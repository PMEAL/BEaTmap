{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "require(\n",
    "        [\"notebook/js/outputarea\"],\n",
    "        function (oa) {\n",
    "            oa.OutputArea.auto_scroll_threshold = -1;\n",
    "            console.log(\"Setting auto_scroll_threshold to -1\");\n",
    "        });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, clear_output\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this notebook has been hidden by default for easier reading.\n",
    "To toggle the raw code on/off, click <a href=\"javascript:code_toggle()\">here</a>.''')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from prettytable import PrettyTable\n",
    "from ipywidgets import interact, interactive\n",
    "from IPython.display import HTML\n",
    "\n",
    "def max_min(array):\n",
    "    maximum = np.nanmax(array)\n",
    "    minimum = np.nanmin(array[np.nonzero(array)])\n",
    "    max_idx = index_of_value(array, maximum)\n",
    "    min_idx = index_of_value(array, minimum)\n",
    "    return(maximum, max_idx, minimum, min_idx)\n",
    "\n",
    "\n",
    "def mean_ignore0(array):\n",
    "    col = array.sum(0)\n",
    "    n_col = (array != 0).sum(0)\n",
    "    mean = np.sum(col) / np.sum(n_col)\n",
    "    return mean\n",
    "\n",
    "\n",
    "def median_ignore0(array):\n",
    "    m = np.ma.masked_equal(array, 0)\n",
    "    median = np.ma.median(m)\n",
    "    return median\n",
    "\n",
    "\n",
    "def index_of_value(array, value):\n",
    "    X = np.abs(array - value)\n",
    "    idx = np.where(X == X.min())\n",
    "    return idx\n",
    "\n",
    "\n",
    "def lin_interp(df, val):\n",
    "    hindex = len(df[df['n'] <= val])\n",
    "    lindex = hindex - 1\n",
    "\n",
    "    m = (df.loc[hindex, 'relp'] - df.loc[lindex, 'relp']) /\\\n",
    "        (df.loc[hindex, 'n'] - df.loc[lindex, 'n'])\n",
    "    b = df.loc[hindex, 'relp'] - df.loc[hindex, 'n'] * m\n",
    "    interp_val = m * val + b\n",
    "    return interp_val\n",
    "\n",
    "def import_dvs_data(file):\n",
    "    data = pd.read_csv('raw_data/' + file)\n",
    "    # this is all just cleaning up the imported csv data\n",
    "    labels = list(data)\n",
    "    del data[labels[6]]\n",
    "    del data[labels[7]]\n",
    "    del data[labels[8]]\n",
    "    del data[labels[9]]\n",
    "    del data[labels[10]]\n",
    "    del data[labels[11]]\n",
    "\n",
    "    labels = list(data)\n",
    "    data.rename(columns={labels[0]: 'conc', labels[1]: 'massch',\n",
    "                         labels[2]: 'p', labels[3]: 'n', labels[4]: 'relp',\n",
    "                         labels[5]: 'bet'}, inplace=True)\n",
    "\n",
    "    # makes a new colum of n(p0-p) aka check1 to be used in validity \"mask\"\n",
    "    data['check1'] = data.n * (1 - data.relp)\n",
    "    return data\n",
    "\n",
    "def get_adsorbate(df):\n",
    "    ads_xc = {\n",
    "        '1,4 - dioxane': 31.4,\n",
    "        '1 - butanol': 41.2,\n",
    "        '1 - hexanol': 65.4,\n",
    "        '1 - pentanol': 57.4,\n",
    "        '1 - propanol': 40.2,\n",
    "        '2 - propanol': 43.2,\n",
    "        'acetone': 34,\n",
    "        'acetonitrile': 21.44,\n",
    "        'benzene': 41,\n",
    "        'butyl acetate': 39.6025,\n",
    "        'carbon tetracholoride': 46,\n",
    "        'chloroform': 44,\n",
    "        'cyclohexane': 39,\n",
    "        'decane': 75,\n",
    "        'dichloromethane': 24.5,\n",
    "        'dodecane': 87,\n",
    "        'ethanol': 35.3,\n",
    "        'ethyl acetate': 33,\n",
    "        'heptadecane': 116.2,\n",
    "        'heptane': 57.3,\n",
    "        'hexadecane': 110,\n",
    "        'hexane': 51.5,\n",
    "        'methanol': 24.1,\n",
    "        'methyl salicylate': 39.2,\n",
    "        'nonane': 69,\n",
    "        'octane': 63,\n",
    "        'pentadecane': 104,\n",
    "        'pentane': 46,\n",
    "        'tetradecane': 98.5,\n",
    "        'tetrahydrofuran': 29,\n",
    "        'toluene': 46,\n",
    "        'tridecane': 92.7,\n",
    "        'undecane': 81,\n",
    "        'water': 10.5\n",
    "        }\n",
    "\n",
    "# dictionary of adsorbate vapor pressures, Torr, from dvs analysis software\n",
    "# unless otherwise noted, used to figure out which adsorbate data is from\n",
    "    ads_vp = {\n",
    "        '1,4 - dioxane': 39.326,\n",
    "        '1 - butanol': 7.193,\n",
    "        '1 - hexanol': 1.025,\n",
    "        '1 - pentanol': 14.547,  # pubchem value is 2.2, very different\n",
    "        '1 - propanol': 21.0,  # pubchem value, no value in dvs software\n",
    "        '2 - propanol': 42.478,\n",
    "        'acetone': 220.150,\n",
    "        'acetonitrile': 88.8,  # pubchem value, no value in dvs software\n",
    "        'benzene': 93.007,\n",
    "        'butyl acetate': 19.193,\n",
    "        'carbon tetracholoride': 109.126,\n",
    "        'chloroform': 190.864,\n",
    "        'cyclohexane': 97.156,\n",
    "        'decane': 1.702,\n",
    "        'dichloromethane': 394.909,\n",
    "        'dodecane': .239,\n",
    "        'ethanol': 55.495,\n",
    "        'ethyl acetate': 90.428,\n",
    "        'heptadecane': .916,  # pubchem value is .000228, very different\n",
    "        'heptane': 45.566,\n",
    "        'hexadecane': .004,\n",
    "        'hexane': 149.775,\n",
    "        'methanol': 123.959,\n",
    "        'methyl salicylate': .149,\n",
    "        'nonane': 4.736,\n",
    "        'octane': 13.517,\n",
    "        'pentadecane': .011,\n",
    "        'pentane': 509.934,\n",
    "        'tetradecane': .032,\n",
    "        'tetrahydrofuran': 55.014,  # pubchem value is 162, very different\n",
    "        'toluene': 27.880,\n",
    "        'tridecane': .102,\n",
    "        'undecane': .600,\n",
    "        'water': 23.558\n",
    "        }\n",
    "    target = df.p[2] / df.relp[2]\n",
    "    adsorbate, ads_vapor_pres = min(ads_vp.items(), key=lambda\n",
    "                                    kv: abs(kv[1] - target))\n",
    "    ads_xc_area = ads_xc.get(adsorbate, \"err not found\")\n",
    "    return adsorbate, ads_vapor_pres, ads_xc_area\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BET\n",
    "\n",
    "This notebook aims to provide a better understanding of Brunauer–Emmett–Teller (BET) theory, and, hopefully, a more accurate specific surface area answer.\n",
    "\n",
    "Analysis of adsorption isotherms by BET theory is easily done, and easily done incorrectly.\n",
    "\n",
    "For a comprehensive background on BET theory, Wikipedia isn't a bad place to start: [https://en.wikipedia.org/wiki/BET_theory](https://en.wikipedia.org/wiki/BET_theory) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting Your Data for Import\n",
    "\n",
    "This notebook imports comma separated variable (CSV) files of a specific format. The CSV file should have twelve (12) columns of data, the first row being coulmn headers, followed by a row for each relative pressure stage. This 12 column table is the output of the DVS software's \"AdvBET\" tool. Here is an example of AdvBET's output:\n",
    "\n",
    "<img src=\"please_dont_delete/bet_adv_example_table.png\">\n",
    "\n",
    "Simply copy this table into a CSV file and the formatting should be acceptable.\n",
    "\n",
    "The notebook will import the table and write all relevant data to a dataframe. The columns of the data frame, from left to right, are: \n",
    " - 'conc', the adsorbate concentration on a scale from 0 to 100%\n",
    " - 'massch', the change in mass, from the reference mass, in milligrams (mg)\n",
    " - 'p', the partial pressure of the adsorbate\n",
    " - 'n', the number of moles of adsorbate adsorbed onto the sample, solved from 'massch'\n",
    " - 'relp', the relative pressure of the adsorbate\n",
    " - 'bet', the dependent term in the BET equation, $\\frac{\\frac{P}{P_o}}{n (1-\\frac{P}{P_o})}$ setting x to the relative pressure, $x = \\frac{P}{P_o}$ makes this term is more neatly written as $\\frac{x}{n (1-x)}$ \n",
    " - 'check1', $n (P_o - P)$, is a value used to check the validity of BET theory over a relative pressure interval\n",
    " \n",
    "After creating a correctly formatted CSV file, save it in the **raw\\_data** folder. You will need to provide the file name in this notebook to import your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter file name:vulcan_chex.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File raw_data/vulcan_chex.csv does not exist: 'raw_data/vulcan_chex.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8444dc2f4e6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter file name:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_dvs_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0madsorbate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mads_vapor_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mads_xc_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_adsorbate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_quality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dd4fe1ed5e4e>\u001b[0m in \u001b[0;36mimport_dvs_data\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimport_dvs_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     \u001b[0;31m# this is all just cleaning up the imported csv data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File raw_data/vulcan_chex.csv does not exist: 'raw_data/vulcan_chex.csv'"
     ]
    }
   ],
   "source": [
    "file = input('Enter file name:')\n",
    "df = import_dvs_data(file)\n",
    "adsorbate, ads_vapor_p, ads_xc_area = get_adsorbate(df)\n",
    "\n",
    "def data_quality(df):\n",
    "    \"\"\"Checks the quality of the isotherm data.\n",
    "\n",
    "    Checks data quality on the assumption that the amount adsorbed increases as\n",
    "    the relative pressure of the adsorbate increases.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        contains adsorption data and values computed from adsortion data\n",
    "\n",
    "    Returns\n",
    "    _______\n",
    "    \n",
    "    printed statements concerning data quality\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    test = np.zeros(len(df))\n",
    "    minus1 = np.concatenate(([0], df.n[: -1]))\n",
    "    test = df.n - minus1\n",
    "    test_sum = sum(x < 0 for x in test)\n",
    "    if test_sum > 0:\n",
    "        print(\"\"\"\\nIsotherm data is suspect.\n",
    "Adsorbed moles do not consistantly increase as relative pressure increases\"\"\")\n",
    "    else:\n",
    "        print(\"\"\"\\nIsotherm data quality appears good.\n",
    "Adsorbed molar amounts are increasing as relative pressure increases.\"\"\")\n",
    "    return\n",
    "\n",
    "def isotherm_type(df):\n",
    "    x = df.relp.values\n",
    "    y = df.n.values\n",
    "    \n",
    "    dist = np.sqrt((x[:-1] - x[1:])**2 + (y[:-1] - y[1:])**2)\n",
    "    dist_along = np.concatenate(([0], dist.cumsum()))\n",
    "    \n",
    "    # build a spline representation of the contour\n",
    "    spline, u = sp.interpolate.splprep([x, y], u=dist_along, w = np.multiply(1, np.ones(len(x))), s = .0000000001)\n",
    "    interp_d = np.linspace(dist_along[0], dist_along[-1], 50) #len(x)\n",
    "    interp_x, interp_y = sp.interpolate.splev(interp_d, spline)\n",
    "    \n",
    "    # take derivative of the spline (to find inflection points)\n",
    "    spline_1deriv = np.diff(interp_y)/np.diff(interp_x)\n",
    "    spline_2deriv = np.diff(spline_1deriv)/np.diff(interp_x[1:])\n",
    "    \n",
    "    zero_crossings = np.where(np.diff(np.sign(spline_2deriv)))[0]\n",
    "\n",
    "    if len(zero_crossings) == 0 and np.sign(spline_2deriv[0]) == -1:\n",
    "        print('Isotherm is type I.')\n",
    "    elif len(zero_crossings) == 0 and np.sign(spline_2deriv[0]) == 1:\n",
    "        print('Isotherm is type III.')\n",
    "    elif len(zero_crossings) == 1 and np.sign(spline_2deriv[0]) == -1:\n",
    "        print('Isotherm is type II.')\n",
    "    elif len(zero_crossings) == 1 and np.sign(spline_2deriv[0]) == 1:\n",
    "        print('Isotherm is type V.')\n",
    "    elif len(zero_crossings) == 2 and np.sign(spline_2deriv[0]) ==-1:\n",
    "        print('Isotherm is type IV.')\n",
    "    else:\n",
    "        print('Isotherm is type VI.')\n",
    "    return\n",
    "\n",
    "def experimental_isotherm_plot(df):\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    ax.plot(df.relp, df.n, c='grey', marker='o', linewidth=0)\n",
    "    ax.set_title('Experimental Isotherm')\n",
    "    ax.set_ylabel('n [mol/g]')\n",
    "    ax.set_xlabel('P/Po')\n",
    "    ax.grid(b=True, which='major', color='gray', linestyle='-')\n",
    "    plt.show()\n",
    "    return()\n",
    "\n",
    "    ads = select_adsorbate.value\n",
    "    ads_prop = ads_info.get(ads, \"\")\n",
    "    ads_xc = ads_prop[0]\n",
    "    ads_vp = ads_prop[1]\n",
    "    data_quality(df)\n",
    "    isotherm_type(df)\n",
    "\n",
    "print('\\nAdsorbate used was %s with a vapor pressure of %.2f mmHg and an adsorbed cross sectional area of %.2f square angstrom.'\n",
    "      % (adsorbate, ads_vapor_p, ads_xc_area))\n",
    "print('\\n', df)\n",
    "data_quality(df)\n",
    "isotherm_type(df)\n",
    "experimental_isotherm_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BET theory is typically applied over a relative pressure range of .5 to .35 and provides a single specific surface area, unique to that relative pressure interval.\n",
    "\n",
    "The results of \"conventional\" BET analysis is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conventionalbet(df, ads_area):\n",
    "    start_index = index_of_value (df.relp, .05)\n",
    "    start = int(start_index[0])\n",
    "    stop_index = index_of_value(df.relp,.35)\n",
    "    stop = int(stop_index[0]) + 1\n",
    "    \n",
    "    a = df.iloc[start:stop, 3:6]\n",
    "    slope, intercept, r_value, p_value, std_err = sp.stats.linregress(a.relp, a.bet)\n",
    "    c = slope/intercept + 1\n",
    "    nm = 1 / (intercept * c)\n",
    "    avagadro = 6.022*10**23\n",
    "    spec_sa = nm * avagadro * ads_area * 10**-20\n",
    "    return(slope, intercept, r_value, c, nm, spec_sa, a.relp, a.bet)\n",
    "\n",
    "def conventionalbetplot(slope, intercept, r_value,  relp, bet, file_name):\n",
    "    min_liney = np.zeros(2)\n",
    "    min_liney[0] = slope * .05 + intercept\n",
    "    min_liney[1] = slope * .35 + intercept\n",
    "    min_linex = np.zeros(2)\n",
    "    min_linex[0] = .05\n",
    "    min_linex[1] = .35\n",
    "    \n",
    "    plt.figure(1, figsize=(10, 10))\n",
    "    plt.title('BET Plot')\n",
    "    plt.xlim(min_linex[0]-.01, min_linex[1]+.01)\n",
    "    plt.ylabel('1/[n(1-Po/P)]')\n",
    "    plt.xlabel('P/Po')\n",
    "    plt.grid(b=True, which='major', color='gray', linestyle='-')\n",
    "    plt.plot(relp, bet,\n",
    "             label='Experimental Data', c='grey', marker='o', linewidth=0)\n",
    "    plt.plot(min_linex, min_liney, color='black', label='Linear Regression')\n",
    "    plt.legend(loc='upper left', framealpha=1)\n",
    "    plt.annotate('Linear Regression: \\nm = %.3f \\nb = %.3f \\nR = %.3f'\n",
    "                 % (slope, intercept, r_value),\n",
    "                 bbox=dict(boxstyle=\"round\", fc='white', ec=\"gray\", alpha=1),\n",
    "                 textcoords='axes fraction', xytext=(.79, .018),\n",
    "                 xy=(.35, min(bet)), size=11)\n",
    "    plt.show()\n",
    "    plt.savefig('output/conventional_bet_plot_%s.png' % (file_name[:-4]), bbox_inches='tight')\n",
    "    return()\n",
    "\n",
    "m, b, r, conventional_c, conventional_nm, conventional_ssa, conventional_relp, bet = conventionalbet(df, ads_xc_area)\n",
    "conventionalbetplot(m, b, r, conventional_relp, bet, file)\n",
    "\n",
    "conventional_bet_table = PrettyTable()\n",
    "conventional_bet_table.field_names = ['Spec SA [m2/g]', 'C', 'nm [mol/g]','Start P/Po', 'End P/Po']\n",
    "conventional_ssa = round(conventional_ssa, 3)\n",
    "conventional_c = round(conventional_c, 3)\n",
    "conventional_nm = round(conventional_nm, 6)\n",
    "\n",
    "\n",
    "conventional_bet_table.add_row([conventional_ssa, conventional_c, conventional_nm, min(conventional_relp), max(conventional_relp)])\n",
    "print(conventional_bet_table)\n",
    "tables = str(conventional_bet_table) \n",
    "with open('output/conventional_bet_table_%s.txt' % (file[:-4]), 'w') as w:\n",
    "    w.write(tables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your data the BET plot may not have a linear trend. This is an indicaiton that BET theory is not applicable to the adsorption data in the relative pressure range of .5 to .35. \n",
    "\n",
    "However, one can apply the BET equation to all relative pressure ranges, and check that the experimental adsorption data jives with BET theory for each relative pressure range. Rather than butcher an explanation of it means to \"jive\" with BET theory, [here](files/please_dont_delete/Is_the_BET_Equation_Applicable_to_Microporous_Adsorbents.pdf) is a well done article explaining BET theory applicablity. **REFERENCE** \n",
    "\n",
    "Below is a heatmap where the shading of each cell corresponds to the BET specific surface area over the relative pressure range. Starting relative pressure is defined by the cell's x coordinate, ending relative pressure defined by the y coordinate.\n",
    "\n",
    "Only cells (relative pressure ranges) containing at least five (5) datapoints and where BET theory is valid are displayed. All other cells are masked, appearing white. An explanation of what it means for BET theory to be valid over a realtive pressure range is provided below the heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bet(df, ads_xc):\n",
    "    \"\"\"Performs BET analysis on an isotherm data set for all relative pressure ranges.\n",
    "    This is the meat and potatoes of the whole package.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    sa_array : array\n",
    "        2D array of BET specific surface areas, the coordinates of the array\n",
    "        corresponding to relative pressures, units [square meter / gram]\n",
    "    \n",
    "    c_array : array\n",
    "        2D array of BET constants, the coordinates of the array\n",
    "        corresponding to relative pressures\n",
    "    \n",
    "    nm_array : array\n",
    "        2D array of BET specific amount of adsorbate in the monolayer, the coordinates of the array\n",
    "        corresponding to relative pressures, units [moles / gram]\n",
    "    \n",
    "    err_array : array\n",
    "        2D array of error between experimental data and BET theoretical isotherms,\n",
    "        the coordinates of the array corresponding to relative pressures\n",
    "    \n",
    "    lin_reg : array\n",
    "        3D array, x by x by 3 where x is the number of experimental data points\n",
    "        the x and x corrdinates corresponding to relative pressure\n",
    "        this array is available for reference and BET theory checks\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sa_array = np.zeros((len(df), len(df)))\n",
    "    c_array = np.zeros((len(df), len(df)))\n",
    "    nm_array = np.zeros((len(df), len(df)))\n",
    "    err_array = np.zeros((len(df), len(df)))\n",
    "    lin_reg = np.zeros((len(df), len(df), 3))\n",
    "    i = 1  # starting at index 1 makes sure that the 0 P/Po data points used\n",
    "    while i < len(df):\n",
    "        j = 1\n",
    "        while j < len(df) and i > j:\n",
    "            a = df.iloc[j:i+1]  # check/confirm indexing \"i+1\"\n",
    "            X = a.relp\n",
    "            y = a.bet\n",
    "            slope, intercept, r_value, p_value, std_err =\\\n",
    "                sp.stats.linregress(X, y)\n",
    "\n",
    "            lin_reg[i, j, 0] = slope\n",
    "            lin_reg[i, j, 1] = intercept\n",
    "            lin_reg[i, j, 2] = r_value\n",
    "            c = slope/intercept + 1\n",
    "            nm = 1 / (intercept * c)\n",
    "            avagadro = 6.022*10**23\n",
    "            spec_sa = nm * avagadro * ads_xc * 10**-20\n",
    "            sa_array[i, j] = spec_sa\n",
    "            c_array[i, j] = c\n",
    "            nm_array[i, j] = nm\n",
    "            bet_c = np.zeros(len(df.relp))\n",
    "            bet_c = (1 / (nm * c)) + (c - 1) * df.relp / (nm * c)\n",
    "            errors = np.nan_to_num(abs(bet_c - df.bet))\n",
    "            err_array[i, j] = sum(errors[j:i + 1]) / (i + 1 - j)\n",
    "            # error is normalized for the interval of relative pressures used\n",
    "            # to compute C\n",
    "            # so, min and max error corresponds to the best and worst fit over\n",
    "            # the interval used in BET analysis, not the entire isotherm\n",
    "            j += 1\n",
    "        i += 1\n",
    "        np.nan_to_num(lin_reg)\n",
    "    return sa_array, c_array, nm_array, err_array, lin_reg\n",
    "\n",
    "\n",
    "# checks that n(p-po) is increasing over BET interval\n",
    "# sloppy in that it creates a mask for the whole array\n",
    "# but works because of how sa array has zeros when j>=i\n",
    "def check_1(df):\n",
    "    \"\"\"Checks that n(p-po) aka check1 is increasing over the relative pressure range used in BET analysis.\n",
    "    This is a necessary condition for linearity of the BET dataset.\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to relative pressure ranges where\n",
    "        n(p-po) isn't consistently increasing with relative pressure\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #is having mask and test arrays redundant?\n",
    "    mask = np.ones((len(df), len(df)))\n",
    "    minus1 = np.concatenate(([0], df.check1[: -1]))\n",
    "    test = (df.check1 - minus1 >= 0)\n",
    "    test = np.tile(test, (len(df), 1))\n",
    "    mask = mask * test\n",
    "    mask = mask.T\n",
    "    return mask\n",
    "\n",
    "\n",
    "# checks that y int from bet plot is positive\n",
    "def check_2(lin_reg):\n",
    "    \"\"\"Checks that y intercept of the BET plot's fit line is positive.\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    lin_reg : array\n",
    "        3D array of linear regression data where [i, j, 1] contains\n",
    "        y-intercept values\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to relative pressure ranges where\n",
    "        the y-intercept is negative or zero\n",
    "    \"\"\"\n",
    "    \n",
    "    mask = (lin_reg[:, :, 1] > 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "# checks that nm is in range of experimental n values used in BET\n",
    "def check_3(df, nm):\n",
    "    \"\"\"Checks that nm, amount adsorbed in the monolayer, is in the range of\n",
    "    data points used in BET analysis\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "    \n",
    "    nm : array\n",
    "        2D array of BET specific amount of adsorbate in the monolayer, the coordinates of the array\n",
    "        corresponding to relative pressures, units [moles / gram]\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to relative pressure ranges nm is not included\n",
    "        in the range of experimental n values\n",
    "    \"\"\"\n",
    "    mask = np.ones((len(df), len(df)))\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        j = 0\n",
    "        while j < len(df):\n",
    "            if df.iloc[j, 3] <= nm[i, j] <= df.iloc[i, 3]:\n",
    "                j += 1\n",
    "            else:\n",
    "                mask[i, j] = 0\n",
    "                j += 1\n",
    "        i += 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "# checks that relp at nm and relp found from setting n = nm in BET eq agree\n",
    "# sloppy in the same way as mask1\n",
    "def check_4(df, lin_reg, nm):\n",
    "    \"\"\"Checks that relative pressure is consistent.\n",
    "    The relative pressure corresponding to nm is found from linear \n",
    "    interpolation of the experiemental data. A second relative pressure is\n",
    "    found by setting n to nm in the BET equation and solving for relative\n",
    "    pressure. The two relative pressures are compared and must agree within 10%\n",
    "    to pass this check.\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "        \n",
    "    lin_reg : array\n",
    "        3D array of linear regression data where [i, j, 1] contains\n",
    "        y-intercept values\n",
    "    \n",
    "    nm : array\n",
    "        2D array of BET specific amount of adsorbate in the monolayer,\n",
    "        the coordinates of the array corresponding to relative pressures,\n",
    "        units [moles / gram]\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to relative pressure values that\n",
    "        do not agree within 10%\n",
    "    \"\"\"\n",
    "    mask = np.ones((len(df), len(df)))\n",
    "    \n",
    "    i = 1\n",
    "    while i < len(df)-1:\n",
    "        j = 1\n",
    "        while j < len(df)-1 and nm[i,j] != 0:\n",
    "            relpm = lin_interp(df, nm[i, j])\n",
    "            coeff = [-1 * lin_reg[i, j, 0] * nm[i, j], lin_reg[i, j, 0]\n",
    "                     * nm[i, j] - 1 - lin_reg[i, j, 1] * nm[i, j],\n",
    "                     lin_reg[i, j, 1] * nm[i, j]]\n",
    "            roots = np.roots(coeff)  # note: some of the roots are imaginary\n",
    "            roots = [item.real for item in roots if len(roots) == 2]\n",
    "            if len(roots) == 2:\n",
    "                relp_m = roots[1]\n",
    "                diff = (relp_m - relpm) / relpm\n",
    "                if abs(diff) > .1:\n",
    "                    mask[i, j] = 0\n",
    "                j += 1\n",
    "            else:\n",
    "                j +=1\n",
    "                \n",
    "        i += 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "# check that range of values used in BET contain certain number of datapoints\n",
    "def check_5(df, points):\n",
    "    \"\"\"Checks that relative pressure ranges contain a minium number of data points.\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "        \n",
    "    points : int\n",
    "        minimum number of data points required for BET analysis to be considered valid\n",
    "        default value is 5\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to ranges of experimental data\n",
    "        that contain less than the minimum number of points\n",
    "    \"\"\"\n",
    "    mask = np.ones((len(df), len(df)))\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        j = 0\n",
    "        while j < len(df):\n",
    "            if i - j < points - 1:\n",
    "                mask[i, j] = 0\n",
    "                j += 1\n",
    "            else:\n",
    "                j += 1\n",
    "        i += 1\n",
    "    return mask\n",
    "\n",
    "def combine_masks(df, linreg, nm):\n",
    "    \"\"\"Calls all check functions and combines their masks into one \"combomask\".\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "        \n",
    "    lin_reg : array\n",
    "        3D array of linear regression data where [i, j, 1] contains\n",
    "        y-intercept values\n",
    "    \n",
    "    nm : array\n",
    "        2D array of BET specific amount of adsorbate in the monolayer, the coordinates of the array\n",
    "        corresponding to relative pressures, units [moles / gram]\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    mask : array\n",
    "        array of 1s and 0s where 0 corresponds to relative pressure ranges that fail one or more checks\n",
    "    \"\"\"\n",
    "    mask1 = check_1(df)\n",
    "    mask2 = check_2(linreg)\n",
    "    mask3 = check_3(df, nm)\n",
    "    mask4 = check_4(df, linreg, nm)\n",
    "    mask5 = check_5(df, 5)\n",
    "\n",
    "    mask = np.multiply(mask1, mask2)\n",
    "    mask = np.multiply(mask3, mask)\n",
    "    mask = np.multiply(mask4, mask)\n",
    "    mask = np.multiply(mask5, mask)\n",
    "    return mask\n",
    "\n",
    "sa, c, nm, err, linreg = bet(df, ads_xc_area)\n",
    "mask = combine_masks(df, linreg, nm)\n",
    "masked_sa = np.multiply(sa, mask)\n",
    "\n",
    "def sa_heatmap(df, sa, file_name):\n",
    "    \"\"\"Creates a heatmap of specific surface areas.\n",
    "\n",
    "    Shading corresponds to specific surface area, normalized for the minimum and maximum spec sa values.\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental data, used to label heatmap axis\n",
    "\n",
    "    sa : array\n",
    "        array of specific surface area values, resulting from BET analysis\n",
    "        if the array has had masks applied to it the resulting heatmap will be masked\n",
    "\n",
    "    file_name : str\n",
    "        file name used to import .csv data, this function uses it to name the output .png file\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    none\n",
    "\n",
    "    Saves image file in same directory as figures.py code\n",
    "    *CHANGE OUTPUT LOC BEFORE PACKAGING?!*\n",
    "\n",
    "    \"\"\"\n",
    "    # finding max and min sa to normalize heatmap colours\n",
    "    samax, sa_max_idx, samin, sa_min_idx = max_min(sa)\n",
    "\n",
    "    hm_labels = round(df.relp * 100, 1)\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(13, 13))\n",
    "    sns.heatmap(sa, vmin=samin, vmax=samax, square=True, cmap='Greens',\n",
    "                mask=(sa==0), xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('Start Relative Pressure')\n",
    "    plt.ylabel('End Relative Pressure')\n",
    "    fig.subplots_adjust(top=.98)\n",
    "    fig.suptitle('BET Analysis Specific Surface Area')\n",
    "    fig.savefig('output/ssa_heatmap_%s.png' % (file_name[:-4]), bbox_inches='tight')\n",
    "    return()\n",
    "\n",
    "sa_heatmap(df, masked_sa, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Five Checks\n",
    "\n",
    "The five checks for BET validity can be grouped into three categories. The first two checks are \"validity\" checks, the second two checks are \"consistency\" checks, and the fifth check is just a minimum number of data points, set by the user, to be considered a valid relative pressure range.\n",
    "\n",
    "Check 1: n(Po-P) must increase as relative pressure inceases.\n",
    "\n",
    "Check 2: positive y-intercept of BET equation (ie positive 'C', the BET constant).\n",
    "\n",
    "Check 3: the monolayer adsorbed amount, nm, must fall within the range of adsorbed amounts of the relative pressure interval.\n",
    "\n",
    "Check 4: n is set to nm in the BET equation, and the equation is solved for relative pressure. This pressure is then check with the relative pressure corresopnding to monolayer completion and must agree within 10%.\n",
    "\n",
    "Check 5: the minimum number of data points required for a relative pressure range to be considered valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_picker(df, linreg, sa, nm, c1, c2, c3, c4, c5, c5_points):\n",
    "    if c1 == True:\n",
    "        mask1 = check_1(df)\n",
    "    else:\n",
    "        mask1 = np.ones((len(df), len(df)))\n",
    "        \n",
    "    if c2 == True:\n",
    "        mask2 = check_2(linreg)\n",
    "    else:\n",
    "        mask2 = np.ones((len(df), len(df)))\n",
    "        \n",
    "    if c3 == True: \n",
    "        mask3 = check_3(df, nm)\n",
    "    else:\n",
    "        mask3 = np.ones((len(df), len(df)))\n",
    "        \n",
    "    if c4 == True:    \n",
    "        mask4 = check_4(df, linreg, nm)\n",
    "    else:\n",
    "        mask4 = np.ones((len(df), len(df)))\n",
    "        \n",
    "    if c5 == True:  \n",
    "        mask5 = check_5(df, c5_points)\n",
    "    else:\n",
    "        mask5 = np.ones((len(df), len(df)))\n",
    "    mask = np.ones((len(df), len(df)))\n",
    "    #mask = np.tril(mask, -1)\n",
    "    mask = np.multiply(mask1, mask)\n",
    "    mask = np.multiply(mask2, mask)\n",
    "    mask = np.multiply(mask3, mask)\n",
    "    mask = np.multiply(mask4, mask)\n",
    "    mask = np.multiply(mask5, mask)\n",
    "    return(mask)  \n",
    "\n",
    "def plotting(Check_1=True, Check_2=True, Check_3=True, Check_4=True, Check_5=True, Min_Points=5):\n",
    "    global custom_mask \n",
    "    custom_mask = mask_picker(df, linreg, sa, nm, Check_1, Check_2, Check_3, Check_4, Check_5, Min_Points)\n",
    "    ssa = np.multiply(sa, custom_mask)\n",
    "    ssa = np.nan_to_num(ssa)\n",
    "\n",
    "    # finding max and min sa to normalize heatmap colours\n",
    "    samax, sa_max_idx, samin, sa_min_idx = max_min(ssa)\n",
    "\n",
    "    # BET constant with all masks applied\n",
    "    c_masked = np.multiply(c, custom_mask)\n",
    "    c_masked = np.nan_to_num(c_masked)\n",
    "\n",
    "    # error with all masks applied, useful in comparing values of C\n",
    "    err_masked = np.multiply(err, custom_mask)\n",
    "    err_masked = np.nan_to_num(err_masked)\n",
    "    \n",
    "    hm_labels = round(df.relp * 100, 1)\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(13, 13))\n",
    "    sns.heatmap(ssa, vmin=samin, vmax=samax, square=True, cmap='Greens', mask=(ssa==0),\n",
    "                xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('Start Relative Pressure')\n",
    "    plt.ylabel('End Relative Pressure')\n",
    "    fig.subplots_adjust(top=.98)\n",
    "    fig.suptitle('BET Analysis Specific Surface Area')\n",
    "    fig.savefig('output/custom_ssa_heatmap_%s.png' % (file[:-4]), bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "interactive_heatmap = interactive(plotting, Check_1=False, Check_2=False, Check_3=False, Check_4=False, Check_5=False, Min_Points=(1,len(df),1))\n",
    "interactive_heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Heatmaps\n",
    "\n",
    "These heatmaps might provide some insight into your adsorption data...or they might not.\n",
    "\n",
    "Theta = nm/n_median and serves to represent the 'centered-ness' of the monolayer amount of adsorbate, nm. n_median is the median molar amount adsorbed for the relative pressure range. Theta = 1 would indicate that nm = n_median\n",
    "\n",
    "Error is the difference between the experimental data and the theoretical isotherm over the relative pressure interval in question. Lower error means that the theoretical isotherm fits the experimental data well over the given relative pressure region.\n",
    "\n",
    "Difference is the difference between the conventional BET specific surface area, and the BET single point specific surface area. Single point and BET specific surface area should agree more as C, the BET contstant, increases.\n",
    "\n",
    "**The additional heatmaps are built using the custom mask you have defined with the \"Check\" buttons and slider. Should you go back and change the check selection, update the mask on these additional heatmaps by toggling their respective check boxes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def single_point_bet(df, ads_xc):\n",
    "    avagadro = 6.022*10**23\n",
    "    \n",
    "    sa_array = np.zeros((len(df), len(df)))\n",
    "    nm_array = np.zeros((len(df), len(df)))\n",
    "    \n",
    "    i = 1  # starting at index 1 makes sure that the 0 P/Po data points used\n",
    "    while i < len(df):\n",
    "        j = 1\n",
    "        while j < len(df) and i > j:\n",
    "            n_range = df.n[j:i]\n",
    "            relp_range = df.relp[j:i]\n",
    "            n = np.ma.median(n_range)\n",
    "            relp = np.ma.median(relp_range)\n",
    "            \n",
    "            nm_array[i, j] = n * (1-relp)\n",
    "            sa_array[i, j] = n * avagadro * ads_xc * 10**-20\n",
    "            j += 1\n",
    "        i += 1\n",
    "    return sa_array, nm_array\n",
    "\n",
    "# function currently not being used\n",
    "def theta(df, nm):\n",
    "    \"\"\"Computes \"theta\" for the BET analysis in each pressure range.\n",
    "    theta = n/nm\n",
    "    depending on the choice of n, theta can represent different things\n",
    "    in this case, if n = the median n for the relative pressure range\n",
    "    then theta gives an idea of how \"centered\" nm is in the relative pressure range\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental isothermal adsorption data\n",
    "        \n",
    "    nm : array\n",
    "        2D array of BET specific amount of adsorbate in the monolayer, the coordinates of the array\n",
    "        corresponding to relative pressures, units [moles / gram]\n",
    "    \n",
    "    Returns\n",
    "    _______\n",
    "    theta : array\n",
    "        array of computed theta values, the coordinates of the array corresponding to relative pressures\n",
    "    \n",
    "    \"\"\"\n",
    "    n = np.zeros((len(df), len(df)))\n",
    "    theta = np.zeros((len(df), len(df)))\n",
    "    i = 1\n",
    "    while i < len(df):\n",
    "        j = 1\n",
    "        while j < len(df) and i > j:\n",
    "            n[i, j] = median_ignore0(df.n[j:i + 1])\n",
    "            j += 1\n",
    "        i += 1\n",
    "\n",
    "    theta = np.divide(n, nm, out=np.zeros_like(n), where=nm!=0)\n",
    "    return theta\n",
    "\n",
    "single_sa, single_nm = single_point_bet(df, ads_xc_area)\n",
    "diff = np.subtract(sa, single_sa)\n",
    "\n",
    "theta = theta(df, nm)\n",
    "\n",
    "def theta_heatmap(df, theta, file_name):\n",
    "    \"\"\"Creates a heatmap of theta values.\n",
    "\n",
    "    Shading corresponds to theta, normalized for the minimum and maximum theta values, 0 = white\n",
    "    Can be used to explore correlation between theta in BET analysis and BET specific surface area\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental data, used to label heatmap axis\n",
    "\n",
    "    theta : array\n",
    "        array of theta values, resulting from theta function\n",
    "        if the array has had masks applied to it the resulting heatmap will be masked\n",
    "\n",
    "    file_name : str\n",
    "        file name used to import .csv data, this function uses it to name the output .png file\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    none\n",
    "\n",
    "    Saves image file in same directory as figures.py code\n",
    "    *CHANGE OUTPUT LOC BEFORE PACKAGING?!*\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    thetamax, theta_max_idx, thetamin, theta_min_idx = max_min(theta)\n",
    "\n",
    "    hm_labels = round(df.relp * 100, 1)\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(13, 13))\n",
    "    sns.heatmap(theta, vmin=thetamin, vmax=thetamax, square=True, cmap='PiYG',\n",
    "                center=1, mask=(theta==0), xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('Start Relative Pressure')\n",
    "    plt.ylabel('End Relative Pressure')\n",
    "    fig.subplots_adjust(top=.98)\n",
    "    fig.suptitle('BET Theta (n/nm) where n is Median of Pressure Range')\n",
    "    filename = file_name[:-4]\n",
    "    fig.savefig('output/theta_heatmap_%s.png' % (filename[:-4]), bbox_inches='tight')\n",
    "    return()\n",
    "\n",
    "\n",
    "def err_heatmap(df, err, file_name):\n",
    "    \"\"\"Creates a heatmap of error values.\n",
    "\n",
    "    Shading corresponds to theta, normalized for the minimum and maximum theta values, 0 = white\n",
    "    Can be used to explore correlation between error in BET analysis and BET specific surface area\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental data, used to label heatmap axis\n",
    "\n",
    "    error : array\n",
    "        array of theta values, resulting from error calculation\n",
    "        if the array has had masks applied to it the resulting heatmap will be masked\n",
    "\n",
    "    file_name : str\n",
    "        file name used to import .csv data, this function uses it to name the output .png file\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    none\n",
    "\n",
    "    Saves image file in same directory as figures.py code\n",
    "    *CHANGE OUTPUT LOC BEFORE PACKAGING?!*\n",
    "\n",
    "    \"\"\"\n",
    "    errormax, error_max_idx, errormin, error_min_idx = max_min(err)\n",
    "\n",
    "    hm_labels = round(df.relp * 100, 1)\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(13, 13))\n",
    "    sns.heatmap(err, vmin=0, vmax=errormax, square=True, cmap='Greys', mask=(err==0),\n",
    "                xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('Start Relative Pressure')\n",
    "    plt.ylabel('End Relative Pressure')\n",
    "    fig.subplots_adjust(top=.98)\n",
    "    fig.suptitle('BET Error Between Experimental and Theoretical Isotherms')\n",
    "    filename = file_name[:-4]\n",
    "    fig.savefig('output/error_heatmap_%s.png' % (filename[:-4]), bbox_inches='tight')\n",
    "    return()\n",
    "    \n",
    "    \n",
    "def diff_heatmap(df, diff, file_name):\n",
    "    \"\"\"Creates a heatmap of error values.\n",
    "\n",
    "    Shading corresponds to theta, normalized for the minimum and maximum theta values, 0 = white\n",
    "    Can be used to explore correlation between error in BET analysis and BET specific surface area\n",
    "    \n",
    "    Parameters\n",
    "    __________\n",
    "    df : dataframe\n",
    "        dataframe of imported experimental data, used to label heatmap axis\n",
    "\n",
    "    diff : array\n",
    "        array of difference values, resulting from multipoint - single point\n",
    "        if the array has had masks applied to it the resulting heatmap will be masked\n",
    "\n",
    "    file_name : str\n",
    "        file name used to import .csv data, this function uses it to name the output .png file\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    none\n",
    "\n",
    "    Saves image file in same directory as figures.py code\n",
    "    *CHANGE OUTPUT LOC BEFORE PACKAGING?!*\n",
    "    \"\"\"\n",
    "    diffmax, diff_max_idx, diffmin, diff_min_idx = max_min(diff)\n",
    "\n",
    "    hm_labels = round(df.relp * 100, 1)\n",
    "    fig, (ax) = plt.subplots(1, 1, figsize=(13, 13))\n",
    "    sns.heatmap(diff, vmin=diffmin, vmax=diffmax, square=True, cmap='PuOr',\n",
    "                mask=(diff==0), xticklabels=hm_labels, yticklabels=hm_labels)\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel('Start Relative Pressure')\n",
    "    plt.ylabel('End Relative Pressure')\n",
    "    fig.subplots_adjust(top=.98)\n",
    "    fig.suptitle('BET Difference Between Multipoint and Single Point: Diff = Multi - Single')\n",
    "    filename = file_name[:-4]\n",
    "    fig.savefig('output/diff_heatmap_%s.png' % (filename[:-4]), bbox_inches='tight')\n",
    "    return()\n",
    "\n",
    "def extra_plots(Theta = False, Error = False, Difference = False):\n",
    "        \n",
    "    if Theta == True:\n",
    "        masked_theta = np.multiply(theta, custom_mask)\n",
    "        theta_heatmap(df, masked_theta, file)\n",
    "    if Theta == False:\n",
    "        print('This is a placeholder until you want to see a heatmap of theta values.')\n",
    "        \n",
    "    if Error == True:\n",
    "        masked_err = np.multiply(err, custom_mask)\n",
    "        err_heatmap(df, masked_err, file)\n",
    "    if Error == False:\n",
    "        print('This is a placeholder until you want to see a heatmap of error values.')\n",
    "    \n",
    "    if Difference == True:\n",
    "        masked_diff = np.multiply(diff, custom_mask)\n",
    "        diff_heatmap(df, masked_diff, file)\n",
    "    if Difference == False:\n",
    "        print('This is a placeholder until you want to see a heatmap of difference values.')\n",
    "        \n",
    "    return()\n",
    "\n",
    "extra_heatmaps = interactive(extra_plots, Theta = False, Error = False, Difference = False)\n",
    "extra_heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table\n",
    "**This table is built using the custom mask you have defined with the \"Check\" buttons and slider. Should you go back and change the check selection, update the table by toggling the check box off and on.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ascii_tables(c, sa, err, df, filename):\n",
    "    \"\"\"Creates and populates ASCII formatted tables of BET results.\n",
    "\n",
    "    Parameters\n",
    "    __________\n",
    "    c : array\n",
    "        masked array of BET constant values\n",
    "\n",
    "    sa : array\n",
    "        masked array of specific surface area values\n",
    "\n",
    "    err : array\n",
    "        masked array of error values\n",
    "\n",
    "    df : dataframe\n",
    "        dataframe of imported isotherm\n",
    "        \n",
    "    Returns\n",
    "    _______\n",
    "    none\n",
    "        \n",
    "    \"\"\"\n",
    "    samax, sa_max_idx, samin, sa_min_idx = max_min(sa)\n",
    "    cmax, c_max_idx, cmin, c_min_idx = max_min(c)\n",
    "\n",
    "    samean = mean_ignore0(sa)\n",
    "    samedian = median_ignore0(sa)\n",
    "    cmean = mean_ignore0(c)\n",
    "    cmedian = median_ignore0(c)\n",
    "\n",
    "    sa_std = sa[sa != 0].std()\n",
    "    c_std = c[c != 0].std()\n",
    "\n",
    "    err_max, err_max_idx, err_min, err_min_idx = max_min(err)\n",
    "\n",
    "    cmax_err = float(c[err_max_idx[0], err_max_idx[1]])\n",
    "    cmin_err = float(c[err_min_idx[0], err_min_idx[1]])\n",
    "\n",
    "    # these are just variables to print in tables\n",
    "    sa_min = round(samin, 3)\n",
    "    sa_min_c = round(float(c[sa_min_idx[0], sa_min_idx[1]]), 3)\n",
    "    sa_min_start_ppo = float(df.relp[sa_min_idx[1]])\n",
    "    sa_min_end_ppo = float(df.relp[sa_min_idx[0]])\n",
    "    sa_max = round(samax, 3)\n",
    "    sa_max_c = round(float(c[sa_max_idx[0], sa_max_idx[1]]), 3)\n",
    "    sa_max_start_ppo = round(float(df.relp[sa_max_idx[1]]), 3)\n",
    "    sa_max_end_ppo = round(float(df.relp[sa_max_idx[0]]), 3)\n",
    "    sa_mean = round(samean, 3)\n",
    "    sa_median = round(samedian, 3)\n",
    "\n",
    "    c_min = round(cmin, 3)\n",
    "    c_min_sa = round(float(sa[c_min_idx[0], c_min_idx[1]]), 3)\n",
    "    c_min_start_ppo = round(float(df.relp[c_min_idx[1]]), 3)\n",
    "    c_min_end_ppo = round(float(df.relp[c_min_idx[0]]), 3)\n",
    "    c_min_err = round(float(err[c_min_idx[0], c_min_idx[1]]), 3)\n",
    "    c_max = round(cmax, 3)\n",
    "    c_max_sa = round(float(sa[c_max_idx[0], c_max_idx[1]]), 3)\n",
    "    c_max_start_ppo = round(float(df.relp[c_max_idx[1]]), 3)\n",
    "    c_max_end_ppo = round(float(df.relp[c_max_idx[0]]), 3)\n",
    "    c_max_err = round(float(err[c_max_idx[0], c_max_idx[1]]), 3)\n",
    "    c_mean = round(cmean, 3)\n",
    "    c_median = round(cmedian, 3)\n",
    "    cmin_err = round(cmin_err, 3)\n",
    "    c_min_err_sa = round(float(sa[err_min_idx[0], err_min_idx[1]]), 3)\n",
    "    c_min_err_start_ppo = round(float(df.relp[err_min_idx[1]]), 3)\n",
    "    c_min_err_end_ppo = round(float(df.relp[err_min_idx[0]]), 3)\n",
    "    err_min = round(err_min, 3)\n",
    "    cmax_err = round(cmax_err, 3)\n",
    "    c_max_err_sa = round(float(sa[err_max_idx[0], err_max_idx[1]]), 3)\n",
    "    c_max_err_start_ppo = round(float(df.relp[err_max_idx[1]]), 3)\n",
    "    c_max_err_end_ppo = round(float(df.relp[err_max_idx[0]]), 3)\n",
    "    err_max = round(err_max, 3)\n",
    "\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['', 'Spec SA m2/g', 'C', 'Start P/Po', 'End P/Po']\n",
    "    table.align[''] = 'r'\n",
    "    table.add_row(['Min Spec SA', sa_min, sa_min_c, sa_min_start_ppo,\n",
    "                   sa_min_end_ppo])\n",
    "    table.add_row(['Max Spec SA', sa_max, sa_max_c, sa_max_start_ppo,\n",
    "                   sa_max_end_ppo])\n",
    "    table.add_row(['Mean Spec SA', sa_mean, 'n/a', 'n/a', 'n/a'])\n",
    "    table.add_row(['Median Spec SA', sa_median, 'n/a', 'n/a', 'n/a'])\n",
    "    print(table)\n",
    "    ssa_sdev_string = 'Standard deviation of specific surface area = %.3f' % (sa_std)\n",
    "    print(ssa_sdev_string)\n",
    "\n",
    "    table2 = PrettyTable()\n",
    "    table2.field_names = ['', 'C, BET constant', 'Spec SA', 'Start P/Po',\n",
    "                          'End P/Po', 'error']\n",
    "    table2.align[''] = 'r'\n",
    "    table2.add_row(['Min C', c_min, c_min_sa, c_min_start_ppo, c_min_end_ppo,\n",
    "                    c_min_err])\n",
    "    table2.add_row(['Max C', c_max, c_max_sa, c_max_start_ppo, c_max_end_ppo,\n",
    "                    c_max_err])\n",
    "    table2.add_row(['Mean C', c_mean, 'n/a', 'n/a', 'n/a', 'n/a'])\n",
    "    table2.add_row(['Median C', c_median, 'n/a', 'n/a', 'n/a', 'n/a'])\n",
    "    table2.add_row(['Min Error C', cmin_err, c_min_err_sa, c_min_err_start_ppo,\n",
    "                    c_min_err_end_ppo, err_min])\n",
    "    table2.add_row(['Max Error C', cmax_err, c_max_err_sa, c_max_err_start_ppo,\n",
    "                    c_max_err_end_ppo, err_max])\n",
    "    print(table2)\n",
    "    c_sdev_string = 'Standard deviation of BET constant (C) = %.5f' % (c_std)\n",
    "    print(c_sdev_string)\n",
    "\n",
    "    tables = str(table) + '\\n' + ssa_sdev_string +'\\n' + str(table2) + '\\n' + c_sdev_string\n",
    "    \n",
    "    with open('output/summary_tables_%s.txt' % (filename[:-4]), 'w') as w:\n",
    "        w.write(tables)\n",
    "    return\n",
    "\n",
    "def show_table(Show_table = False):\n",
    "        \n",
    "    if Show_table == True:\n",
    "        custom_masked_c = np.multiply(c, custom_mask)\n",
    "        custom_masked_sa = np.multiply(sa, custom_mask)\n",
    "        custom_masked_err = np.multiply(err, custom_mask)\n",
    "\n",
    "        ascii_tables(custom_masked_c, custom_masked_sa, custom_masked_err, df, file)\n",
    "        \n",
    "    if Show_table == False:\n",
    "        print('This is a place holder until ya wanna see a table.')\n",
    "        \n",
    "    return()\n",
    "\n",
    "show_table_button = interactive(show_table, Show_table = False)\n",
    "show_table_button\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "\n",
    "All figures created in this notebook have been saved as .png files in the **output** folder. Tabular data has also been saved to text files in the same folder. The raw data file name is incorporated into all outputs, hopefully it's unique enough to identify your work.\n",
    "\n",
    "If you'd like to create additional .csv files of your raw data, or the results of this notebook's BET algorithim, use the buttons below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_raw_data(df, file_name):\n",
    "    file_name = file_name[:-4]\n",
    "    export_file_name = 'output/' + file_name + '_raw_data_export.csv'\n",
    "    export_csv = df.to_csv(export_file_name, index=None, header=True)\n",
    "    return\n",
    "\n",
    "def export_processed_data(df, sa, c, nm, lin_reg, file_name):\n",
    "    i = 0\n",
    "    end_relp = np.zeros((len(df), len(df)))\n",
    "    while i < len(df):\n",
    "        end_relp[i:] = df.relp[i]\n",
    "        i += 1\n",
    "\n",
    "    begin_relp = np.transpose(end_relp)\n",
    "\n",
    "    mask1 = check_1(df)\n",
    "    mask2 = check_2(lin_reg)\n",
    "    mask3 = check_3(df, nm)\n",
    "    mask4 = check_4(df, lin_reg, nm)\n",
    "\n",
    "    processed_data = np.column_stack((begin_relp.flatten(), end_relp.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, sa.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, c.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, nm.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, lin_reg[:,:,0].flatten()))\n",
    "    processed_data = np.column_stack((processed_data, lin_reg[:,:,1].flatten()))\n",
    "    processed_data = np.column_stack((processed_data, lin_reg[:,:,2].flatten()))\n",
    "    processed_data = np.column_stack((processed_data, mask1.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, mask2.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, mask3.flatten()))\n",
    "    processed_data = np.column_stack((processed_data, mask4.flatten()))\n",
    "    \n",
    "    processed_data = pd.DataFrame(data=processed_data, columns=['begin relative pressure', 'end relative pressure', 'spec sa [m2/g]',\n",
    "              'bet constant', 'nm [mol/g]', 'slope', 'y-int', 'r value', 'check1',\n",
    "              'check2','check3','check4'])\n",
    "\n",
    "    file_name = file_name[:-4]\n",
    "    export_file_name = 'output/' + file_name + '_processed_data_export.csv'\n",
    "    export_csv = processed_data.to_csv(export_file_name, index=None, header=True)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "def export_data(Raw_data = False, Processed_data = False):\n",
    "        \n",
    "    if Raw_data == True:\n",
    "        export_raw_data(df, file)\n",
    "        \n",
    "    if Processed_data == True:\n",
    "        export_processed_data(df, sa, c, nm, linreg, file)\n",
    "        \n",
    "    return()\n",
    "\n",
    "export_data_buttons = interactive(export_data, Raw_data = False, Processed_data = False)\n",
    "export_data_buttons\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bug Reporting\n",
    "\n",
    "When you inevitably come across a bug, please let me know.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
